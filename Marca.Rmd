---
title: "Marcas"
author: "Alberto Lopez"
date: "25/6/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



## Libraries


Load up the necessary libraries

```{r warning=FALSE, message=FALSE, error=FALSE}
library(rtweet)  # Twitter package
library(dplyr)
library(ggplot2)
library(sf)   # For making maps
library(usmap)
library(reshape2)
# Packages for text analysis and wordcloud
library(tm)
library(syuzhet)
library(tidytext)
library(ggwordcloud)
library(SnowballC)
library(wordcloud)
library(RColorBrewer)
library(readr)
library(readxl)
```


### Load the .csv file with the Brands Tweets

Import the file by clicking on the file and import dataset "marcas".


## Data exploration

Let's see what variable names we have.

```{r}
names(marcas)
```


```{r}
marcas %>% 
  distinct(user_id, source) %>% 
  count(source, sort = TRUE) %>% 
  top_n(10)
```

How many verified accounts do we have in our sample?

```{r}
marcas %>% 
  distinct(user_id, verified) %>% 
  count(verified, sort = TRUE)
```


## Choose your Brand

```{r}
table(marcas$brand)
```

By teams choose a brand to make your analyses

## Make a subdata set with only your brand

```{r}
Amazon <- subset(marcas, brand == "Amazon")
```


## Sentiment analysis


```{r eval = FALSE}
Amazon_sent <- Amazon$text %>% 
    syuzhet::get_nrc_sentiment()
```



```{r}
Amazon_sent %>% 
  summarize_all(sum, na.rm = TRUE) %>% 
  select(-negative, -positive) %>% # Dropping these helps in plotting
  reshape2::melt() %>% 
  ggplot(aes(reorder(variable, -value), value)) +
  geom_col() +
  labs(x = "Sentiment", y = "Frequency of Words") +
  theme_minimal()
```

Plot only positive and negative sentiment.

```{r}
Amazon_sent %>% 
  summarize_all(sum, na.rm = TRUE) %>% 
  select(negative, positive) %>% 
  reshape2::melt() %>% 
  ggplot(aes(reorder(variable, -value), value)) +
  geom_col() +
  labs(x = "Sentiment", y = "Frequency of Words") +
  theme_minimal()
```


## Create a wordcloud

Wordcloud is a popular visualization tool.

Before we can make a wordcloud, there is some preprocessing of the text that is necessary. First of all, we need to tokenize the text so that we have all the words separately identified. Next, we get rid of all the "stop words" such as articles (e.g., the, an), pronouns (e.g., he, she, it), etc. We also need to remove other words that we think may contaminate the wordcloud.^[This requires some trial and error.] 

Create a tibble of all the words we want to get rid of. This list needs to be updated depending on what shows up in the wordcloud below.

```{r}
exclude_words <- tibble(word = c("http", "https", "twitter", "t.co", "amazon", "amp", "gt", "â", "iâ", "1", "2", "3", "2066", "2069", "5", "fe0f"))
```

We have to first get the words from all the tweets

```{r}
Amazon_geo <- lat_lng(Amazon)
word_tokens <- Amazon_geo %>% 
  select(user_id, text) %>% 
  tidytext::unnest_tokens(word, text) %>% 
  anti_join(stop_words) %>% 
  anti_join(exclude_words)
head(word_tokens)
```

The first few words that we see are probably hashtags this user used. We don't need to pay attention to individual words at this point.

Find the frequency of each word and then rank them in descending order

```{r}
word_tokens_count <- word_tokens %>% 
  count(word, sort = TRUE)
head(word_tokens_count)
```

Make the wordcloud

```{r}
set.seed(2019)
word_tokens_count %>% 
  top_n(30) %>% 
  ggplot(aes(label = word, size = n, color = word)) +
  scale_size_area(max_size = 10) +
  geom_text_wordcloud() +
  theme_minimal()
```


### Linear regression

What are the sentiments that make a tweet more popular? how can be make our tweets more popular?

Let's run a regression anaysis to find out!!


```{r}
cbind(Amazon, Amazon_sent) %>% 
  mutate(favorite_count = favorite_count + 1) %>% 
  lm(log(favorite_count) ~ anger + anticipation + disgust + fear + joy +
             sadness + surprise + trust + verified + log(followers_count+1),
           data = .) %>% 
  summary()
```




```{r}
cbind(Amazon, Amazon_sent) %>% 
  mutate(retweet_count = retweet_count + 1) %>% 
  lm(log(retweet_count) ~ anger + anticipation + disgust + fear + joy +
             sadness + surprise + trust + verified + log(followers_count+1),
           data = .) %>% 
  summary()
```